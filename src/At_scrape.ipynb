{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c98ebb",
   "metadata": {},
   "source": [
    "# Extract Autotrader.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db35540",
   "metadata": {},
   "source": [
    "# Extract auto trader Dealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101432d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'pexpect'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Define interactor systems for rotation\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\"\n",
    "]\n",
    "# Set up logging\n",
    "# log_file_path = '/Users/kingcarlos/Imperium/Lead_Generator/Car_Dealerships_LG/Logs/proxy_test_logs.log'\n",
    "log_file_path = os.path.join(os.getcwd(), \"experiments.log\")\n",
    "output_file = os.path.join(os.getcwd(), \"proxy_test_dealers.csv\")\n",
    "driver_path = os.path.join(os.getcwd(), \"chromedriver.exe\")\n",
    "extension_path = os.path.join(os.getcwd(), \"pphgdbgldlmicfdkhondlafkiomnelnk.crx\")\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "async def rest(duration):\n",
    "    logging.info(f\"Resting for {duration:.2f} seconds\")\n",
    "    await asyncio.sleep(duration)\n",
    "\n",
    "async def change_zip_code(driver, zip_code):\n",
    "    try:\n",
    "        logging.info(f'The zip code which I am processing in change_zip_code: {zip_code}')\n",
    "        # Open the location modal and enter the new ZIP code\n",
    "        map_marker_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, 'span.text-bold.text-size-300.text-link span[role=\"button\"]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", map_marker_button)\n",
    "        await rest(2)\n",
    "\n",
    "        zip_input = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'filterLocationZipInput'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].value = '';\", zip_input)\n",
    "        await rest(2)\n",
    "        driver.execute_script(f\"arguments[0].value = '{zip_code}';\", zip_input)\n",
    "        # zip_input.clear()\n",
    "        await rest(1)\n",
    "        # zip_input.send_keys(zip_code)\n",
    "        logging.info(f\"Entered ZIP code: {zip_code}\")\n",
    "        await rest(2)\n",
    "\n",
    "        submit_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn.btn-primary'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", submit_button)\n",
    "        await rest(5)\n",
    "        # logging.info(f'The zip code which I am processing in change_zip_code: {zip_code}')\n",
    "        # # Open the location modal and enter the new ZIP code\n",
    "        # map_marker_button = WebDriverWait(driver, 20).until(\n",
    "        #     EC.element_to_be_clickable((By.CSS_SELECTOR, 'span.text-bold.text-size-300.text-link span[role=\"button\"]'))\n",
    "        # )\n",
    "        # driver.execute_script(\"arguments[0].click();\", map_marker_button)\n",
    "        # # await rest(2)\n",
    "        # time.sleep(2)\n",
    "\n",
    "        # zip_input = WebDriverWait(driver, 20).until(\n",
    "        #     EC.element_to_be_clickable((By.ID, 'filterLocationZipInput'))\n",
    "        # )\n",
    "\n",
    "        # logging.info(f'Before the input field is being cleared')\n",
    "        # zip_input.clear()\n",
    "        # logging.info(f'After the input field is being cleared')\n",
    "        # # await rest(1)\n",
    "        # time.sleep(1)\n",
    "        # zip_input.send_keys(zip_code)\n",
    "        # logging.info(f\"Entered ZIP code: {zip_code}\")\n",
    "        # # await rest(2)\n",
    "        # time.sleep(2)\n",
    "\n",
    "        # submit_button = WebDriverWait(driver, 20).until(\n",
    "        #     EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.btn.btn-primary'))\n",
    "        # )\n",
    "        # driver.execute_script(\"arguments[0].click();\", submit_button)\n",
    "        # # await rest(5)\n",
    "        # time.sleep(5)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to change ZIP code to {zip_code}: {e}\")\n",
    "\n",
    "async def scrape_dealer_data(zip_codes, output_file=output_file, driver_path=driver_path):\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['Dealership Name', 'Address', 'Phone Number', 'Website URL', 'Dealer Details URL', 'Miles']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "    logging.info(f'The zip code I am getting: {zip_codes}')\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "    # Load the VPN extension\n",
    "    chrome_options.add_extension(extension_path)\n",
    "    service = Service(driver_path)\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    try:\n",
    "        existing_dealers = set()\n",
    "        for zip_code in zip_codes:\n",
    "            logging.info(f'The zip code which I am processing: {zip_code}')\n",
    "            logging.info(f\"Processing ZIP code: {zip_code}\")\n",
    "            driver.get('https://www.autotrader.com/car-dealers')\n",
    "            await rest(2)\n",
    "            await change_zip_code(driver, zip_code)\n",
    "            logging.info(f\"Completed processing for ZIP code: {zip_code}\")\n",
    "\n",
    "            waypoint_divs = WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div[data-cmp=\"delayedImpressionWaypoint\"]'))\n",
    "            )\n",
    "            dealer_count = 0\n",
    "            \n",
    "            with open(output_file, 'a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                for div in waypoint_divs:\n",
    "                    if dealer_count >= 3:\n",
    "                        break\n",
    "                    dealership_name = div.find_element(By.CSS_SELECTOR, 'h2.css-1jcwmgy').text\n",
    "                    address = div.find_element(By.CSS_SELECTOR, 'div[data-testid=\"address\"] span').text\n",
    "                    phone_number = div.find_element(By.CSS_SELECTOR, 'span[data-testid=\"phoneNumber\"]').text\n",
    "                    miles = div.find_element(By.CSS_SELECTOR, 'span[data-testid=\"mileageContent\"]').text\n",
    "                    try:\n",
    "                        website_url = div.find_element(By.CSS_SELECTOR, 'div[data-cy=\"secondaryBtn\"] a').get_attribute('href')\n",
    "                    except NoSuchElementException:\n",
    "                        website_url = \"URL Not Found\"\n",
    "                        logging.info(f\"Website URL not found for dealer at '{zip_code}'\")\n",
    "                    \n",
    "                    dealer_details_url = div.find_element(By.CSS_SELECTOR, 'a[href*=\"car-dealers\"]').get_attribute('href')\n",
    "                    \n",
    "                    if (dealership_name, address) not in existing_dealers:\n",
    "                        writer.writerow({\n",
    "                            'Dealership Name': dealership_name,\n",
    "                            'Address': address,\n",
    "                            'Phone Number': phone_number,\n",
    "                            'Website URL': website_url,\n",
    "                            'Dealer Details URL': dealer_details_url,\n",
    "                            'Miles': miles\n",
    "                        })\n",
    "                        existing_dealers.add((dealership_name, address))\n",
    "                        dealer_count += 1\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        df = pd.read_csv(output_file)\n",
    "        df.drop_duplicates(subset=['Dealership Name', 'Address'], keep='first', inplace=True)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        logging.info(\"Duplicates removed from CSV and file saved.\")\n",
    "\n",
    "        # Confirming the output CSV path\n",
    "        if os.path.isfile(output_file):\n",
    "            logging.info(f\"File '{output_file}' exists and has been successfully overwritten.\")\n",
    "        else:\n",
    "            logging.warning(f\"File '{output_file}' could not be found; please confirm file path.\")\n",
    "\n",
    "        def kill_chrome_processes():\n",
    "            for proc in psutil.process_iter():\n",
    "                try:\n",
    "                    if proc.name() in [\"chrome\", \"chromedriver\"]:\n",
    "                        proc.kill()\n",
    "                        logging.info(f\"Terminated process {proc.name()} with PID {proc.pid}\")\n",
    "                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "                    logging.warning(f\"Failed to terminate process with PID {proc.pid}\")\n",
    "\n",
    "        kill_chrome_processes()\n",
    "        logging.info(\"All Chrome processes terminated after CSV operations.\")\n",
    "\n",
    "# Example application\n",
    "zip_codes = [90061, 90066]\n",
    "await scrape_dealer_data(zip_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df237e",
   "metadata": {},
   "source": [
    "Miles, Engine Description, MPG, Transmission, Drive Type, Exterior Color, Interior Color, Price\n",
    "\n",
    "Please paste the actual/referenced/expected csv fiel there in the same directory\n",
    "\n",
    "It is\n",
    "\n",
    "Okay, thank you, please wait....\n",
    "\n",
    "Take your time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d1325",
   "metadata": {},
   "source": [
    "# Extract auto trader Dealer Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758c4d4",
   "metadata": {},
   "source": [
    "{'Dealership Name': 'ROBERTS AUTO INC', 'Address': '642 E Florence Ave\\nLos Angeles CA, 90001', 'Phone Number': '(323) 892-7934', 'Website URL': 'URL Not Found', 'Vehicle Links': 'https://www.autotrader.com/cars-for-sale/vehicle/721720023', 'Dealer Details URL': 'https://www.autotrader.com/car-dealers/los-angeles-ca/71538847/roberts-auto-inc', 'Item': '', 'Model Year': '', 'Condition': '', 'Miles': '', 'Engine Description': '', 'MPG': '', 'Transmission': '', 'Drive Type': '', 'Exterior Color': '', 'Interior Color': '', 'Price': '', 'MSRP': '', 'VIN': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db0763",
   "metadata": {},
   "source": [
    "Ali can you check your whatsapp please? I need to get some rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 00:51:19,218 - Script Started\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kingcarlos/Imperium/Lead_Generator/Car_Dealerships_LG/proxy_test_dealers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 311\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m extract_vehicle_data(vehicle_links, dealer_data, driver_path, output_csv_file)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# Start processing dealer URLs\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m open_dealer_urls(csv_file, output_csv_file, driver_path)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Load the data into a DataFrame for deduplication\u001b[39;00m\n\u001b[0;32m    314\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(output_csv_file)\n",
      "Cell \u001b[1;32mIn[3], line 292\u001b[0m, in \u001b[0;36mopen_dealer_urls\u001b[1;34m(csv_file, output_csv_file, driver_path)\u001b[0m\n\u001b[0;32m    289\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# Read dealer data and process each\u001b[39;00m\n\u001b[1;32m--> 292\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    293\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(file)\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n",
      "File \u001b[1;32mc:\\Users\\akber\\Desktop\\Freelancing\\Scrapping_2\\Scrapes\\Scrapes\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/kingcarlos/Imperium/Lead_Generator/Car_Dealerships_LG/proxy_test_dealers.csv'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import psutil\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Paths\n",
    "csv_file = os.path.join(os.getcwd(), \"proxy_test_dealers.csv\")\n",
    "# output_csv_file = '/Users/kingcarlos/Imperium/Lead_Generator/Car_Dealerships_LG/proxy_test_inventory.csv'\n",
    "output_csv_file = os.path.join(os.getcwd(), \"experiments.csv\")\n",
    "# driver_path = '/Users/kingcarlos/Imperium/Lead_Generator/Car_Dealerships_LG/chromedriver-mac-x64/chromedriver'\n",
    "# log_file_path = '/Users/kingcarlos/Imperium/Lead_Generator/Car_Dealerships_LG/Logs/proxy_test_logs_codeblock2.log'\n",
    "log_file_path = os.path.join(os.getcwd(), \"experiments2.log\")\n",
    "driver_path = os.path.join(os.getcwd(), \"chromedriver.exe\")\n",
    "extension_path = os.path.join(os.getcwd(), \"pphgdbgldlmicfdkhondlafkiomnelnk.crx\")\n",
    "\n",
    "# Setup logging to ensure logs are written to the specified file\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "file_handler = logging.FileHandler(log_file_path, mode='w')\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n",
    "logging.getLogger().addHandler(file_handler)\n",
    "logging.info(\"Script Started\")\n",
    "\n",
    "# User-agent rotation\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\"\n",
    "]\n",
    "\n",
    "async def rest(duration):\n",
    "    logging.info(f\"Resting for {duration:.2f} seconds\")\n",
    "    await asyncio.sleep(duration)\n",
    "\n",
    "def get_scroll_height(driver):\n",
    "    return driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "def split_vehicle_title(title):\n",
    "    parts = title.split()\n",
    "    if len(parts) >= 3:\n",
    "        condition = parts[0]\n",
    "        model_year = parts[1]\n",
    "        item = \" \".join(parts[2:])\n",
    "        return condition, model_year, item\n",
    "    else:\n",
    "        logging.warning(f\"Unexpected title format: '{title}'\")\n",
    "        return \"Unknown\", \"Unknown\", title\n",
    "\n",
    "def extract_mileage(mileage_text):\n",
    "    mileage_parts = mileage_text.split(' ')\n",
    "    mileage = ''.join(filter(str.isdigit, mileage_parts[0]))\n",
    "    return mileage\n",
    "\n",
    "def extract_vin(driver, max_scroll_attempts=10):\n",
    "    vin = None\n",
    "    last_height = get_scroll_height(driver)\n",
    "    scroll_attempts = 0\n",
    "\n",
    "    while scroll_attempts < max_scroll_attempts:\n",
    "        try:\n",
    "            vin_element = driver.find_element(By.XPATH, \"//div[contains(@class, 'text-gray-dark')]//span[contains(text(), 'VIN')]\")\n",
    "            vin_text = vin_element.text\n",
    "            vin = vin_text.split(\":\")[1].strip()  \n",
    "            logging.info(f\"VIN found: {vin}\")\n",
    "            return vin  \n",
    "        except NoSuchElementException:\n",
    "            scroll_attempts += 1\n",
    "            driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "            time.sleep(2)\n",
    "            new_height = get_scroll_height(driver)\n",
    "            if new_height == last_height:\n",
    "                logging.warning(\"Reached the bottom of the page; VIN not found.\")\n",
    "                break\n",
    "            last_height = new_height\n",
    "    return vin\n",
    "\n",
    "def extract_price_and_msrp(price_text):\n",
    "    msrp = \"N/A\"\n",
    "    price = price_text.strip()\n",
    "    if \"MSRP\" in price_text:\n",
    "        msrp_lines = price_text.splitlines()\n",
    "        for i, line in enumerate(msrp_lines):\n",
    "            if \"MSRP\" in line and i > 0:\n",
    "                price = msrp_lines[i - 1].strip()\n",
    "                msrp = line.replace(\"MSRP\", \"\").strip()\n",
    "                break\n",
    "    return price, msrp\n",
    "\n",
    "async def get_vehicle_links(dealer_url, driver_path, max_vehicles=3):\n",
    "    vehicle_links = []\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "    # Load the VPN extension\n",
    "    chrome_options.add_extension(extension_path)\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    try:\n",
    "        driver.get(dealer_url)\n",
    "        await rest(3)\n",
    "        \n",
    "        while len(vehicle_links) < max_vehicles:\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-cmp=\"delayedImpressionWaypoint\"]'))\n",
    "            )\n",
    "            \n",
    "            waypoint_divs = driver.find_elements(By.CSS_SELECTOR, 'div[data-cmp=\"delayedImpressionWaypoint\"]')\n",
    "            new_links = [div.find_element(By.TAG_NAME, 'a').get_attribute('href') for div in waypoint_divs]\n",
    "            \n",
    "            vehicle_links.extend(new_links[:max_vehicles - len(vehicle_links)])\n",
    "            \n",
    "            # Break loop if vehicle links exceed or reach the target\n",
    "            if len(vehicle_links) >= 5:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                next_button = driver.find_element(By.XPATH, '//button[contains(@aria-label, \"Next Page\")]')\n",
    "                next_button.click()\n",
    "                await rest(3)\n",
    "            except (NoSuchElementException, ElementClickInterceptedException):\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching vehicle links: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "    return vehicle_links[:max_vehicles]\n",
    "\n",
    "async def extract_vehicle_data(vehicle_links, dealer_data, driver_path, output_csv_file):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    try:\n",
    "        with open(output_csv_file, 'a', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = [\n",
    "                \"Dealership Name\", \"Address\", \"Phone Number\", \"Website URL\", \"Vehicle Links\",\n",
    "                \"Dealer Details URL\", \"Item\", \"Model Year\", \"Condition\", \"Miles\",\n",
    "                \"Engine Description\", \"MPG\", \"Transmission\", \"Drive Type\",\n",
    "                \"Exterior Color\", \"Interior Color\", \"Price\", \"MSRP\", \"VIN\"\n",
    "            ]\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            \n",
    "            for link in vehicle_links:\n",
    "                logging.info(f'These are the links: {link}')\n",
    "                driver.get(link)\n",
    "                await rest(3)\n",
    "\n",
    "                # Initialize vehicle_data with default keys\n",
    "                vehicle_data = {key: \"\" for key in fieldnames}\n",
    "                vehicle_data.update({\n",
    "                    \"Dealership Name\": dealer_data['Dealership Name'],\n",
    "                    \"Address\": dealer_data['Address'],\n",
    "                    \"Phone Number\": dealer_data['Phone Number'],\n",
    "                    \"Website URL\": dealer_data['Website URL'],\n",
    "                    \"Vehicle Links\": link,\n",
    "                    \"Dealer Details URL\": dealer_data['Dealer Details URL']\n",
    "                })\n",
    "\n",
    "                logging.info(f'This is the vehicle data list: {vehicle_data}')\n",
    "\n",
    "                # logging.info(f'Here is the content of the page: {driver.page_source}')\n",
    "                # break\n",
    "\n",
    "                list_items = WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_all_elements_located((By.XPATH, '//ul[@data-cmp=\"listColumns\"]/li'))\n",
    "                )\n",
    "\n",
    "                # list_items = driver.find_elements(By.XPATH, '//ul[@data-cmp=\"listColumns\"]/li')\n",
    "                vehicle_data = {}\n",
    "                for item in list_items:\n",
    "                    # logging.info(f'Here is the Item which i am getting: {item.text}')\n",
    "                    print(item.text)\n",
    "\n",
    "                # Extracting the Drive Type\n",
    "                # try:\n",
    "                #     drive_type_element = driver.find_element(By.XPATH, 'your_xpath_for_drive_type')\n",
    "                #     vehicle_data[\"Drive Type\"] = drive_type_element.text \n",
    "                    \n",
    "                # except NoSuchElementException:\n",
    "                #     logging.info(f\"Drive Type not found for '{link}' - Skipped.\")\n",
    "\n",
    "                # Extracting the Title and related data\n",
    "                try:\n",
    "                    title_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, 'h1[data-cmp=\"heading\"]'))\n",
    "                    )\n",
    "                    title_text = title_element.text.strip()\n",
    "                    condition, model_year, item = split_vehicle_title(title_text)\n",
    "                    vehicle_data[\"Item\"] = item\n",
    "                    vehicle_data[\"Model Year\"] = model_year\n",
    "                    vehicle_data[\"Condition\"] = condition\n",
    "                except NoSuchElementException:\n",
    "                    logging.warning(f\"Title element not found for '{link}'; using default values.\")\n",
    "                    vehicle_data[\"Item\"] = \"Unknown Item\"\n",
    "                    vehicle_data[\"Model Year\"] = \"Unknown Year\"\n",
    "                    vehicle_data[\"Condition\"] = \"Unknown Condition\"\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Failed to extract title data for '{link}': {e}\")\n",
    "\n",
    "                # Extracting the VIN\n",
    "                try:\n",
    "                    vin = extract_vin(driver, max_scroll_attempts=10)\n",
    "                    vehicle_data[\"VIN\"] = vin\n",
    "                    if vin:\n",
    "                        logging.info(f\"VIN found: {vin}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"VIN not found for '{link}'.\")\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Failed to extract VIN for '{link}': {e}\")\n",
    "                \n",
    "                # Extracting other vehicle details\n",
    "                data_items = driver.find_elements(By.CSS_SELECTOR, 'ul[data-cmp=\"listColumns\"] li')\n",
    "                for item in data_items:\n",
    "                    \n",
    "                    try:\n",
    "                        title = item.find_element(By.CSS_SELECTOR, 'div[aria-label]').get_attribute('aria-label')\n",
    "                        value = item.find_element(By.CLASS_NAME, 'display-flex').text.strip()\n",
    "\n",
    "                        if \"MILEAGE\" in title:\n",
    "                            vehicle_data[\"Miles\"] = extract_mileage(value)\n",
    "                        elif \"ENGINE_DESCRIPTION\" in title:\n",
    "                            vehicle_data[\"Engine Description\"] = value\n",
    "                        elif \"MPG\" in title:\n",
    "                            vehicle_data[\"MPG\"] = value\n",
    "                        elif \"TRANSMISSION\" in title:\n",
    "                            vehicle_data[\"Transmission\"] = value\n",
    "                        elif \"DRIVE TYPE\" in title:\n",
    "                            vehicle_data[\"Drive Type\"] = value\n",
    "                        elif \"Exterior\" in title:\n",
    "                            vehicle_data[\"Exterior Color\"] = value\n",
    "                        elif \"Interior\" in title:\n",
    "                            vehicle_data[\"Interior Color\"] = value\n",
    "                        # elif \"Seats\" in v_value:\n",
    "                        #     vehicle_data[\"Interior Color\"] = v_value\n",
    "                    except NoSuchElementException:\n",
    "                        logging.info(f\"Missing data item for '{link}': {title} - Skipped.\")\n",
    "\n",
    "                # Price extraction\n",
    "                try:\n",
    "                    price_element = driver.find_element(By.CSS_SELECTOR, 'div[data-cmp=\"pricing\"] span[data-cmp=\"firstPrice\"]')\n",
    "                    vehicle_data[\"Price\"], vehicle_data[\"MSRP\"] = extract_price_and_msrp(price_element.text)\n",
    "                except NoSuchElementException:\n",
    "                    logging.info(f\"Price data not found for {link}\")\n",
    "                    vehicle_data[\"Price\"] = \"N/A\"\n",
    "                    vehicle_data[\"MSRP\"] = \"N/A\"\n",
    "\n",
    "                # Write data to CSV\n",
    "                writer.writerow(vehicle_data)\n",
    "                logging.info(f\"Vehicle data saved for {link}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during data extraction for vehicles: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Terminate lingering Chrome processes\n",
    "def kill_chrome_processes():\n",
    "    for proc in psutil.process_iter():\n",
    "        try:\n",
    "            if proc.name() in [\"chrome\", \"chromedriver\"]:\n",
    "                proc.kill()\n",
    "                logging.info(f\"Terminated {proc.name()} with PID {proc.pid}\")\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied):\n",
    "            logging.warning(\"Failed to terminate process\")\n",
    "\n",
    "async def open_dealer_urls(csv_file, output_csv_file, driver_path):\n",
    "    # Open the CSV for writing headers\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\n",
    "            \"Dealership Name\", \"Address\", \"Phone Number\", \"Website URL\", \"Vehicle Links\", \n",
    "            \"Dealer Details URL\", \"Item\", \"Model Year\", \"Condition\", \"Miles\", \n",
    "            \"Engine Description\", \"MPG\", \"Transmission\", \"Drive Type\", \n",
    "            \"Exterior Color\", \"Interior Color\", \"Price\", \"MSRP\", \"VIN\"\n",
    "        ])\n",
    "        writer.writeheader()\n",
    "\n",
    "    # Read dealer data and process each\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            dealer_data = {\n",
    "                \"Dealership Name\": row['Dealership Name'],\n",
    "                \"Address\": row['Address'],\n",
    "                \"Phone Number\": row['Phone Number'],\n",
    "                \"Website URL\": row['Website URL'],\n",
    "                \"Dealer Details URL\": row['Dealer Details URL']\n",
    "            }\n",
    "            \n",
    "            # Log processing information\n",
    "            logging.info(f\"Processing dealer: {dealer_data['Dealership Name']} - URL: {dealer_data['Dealer Details URL']}\")\n",
    "            \n",
    "            vehicle_links = await get_vehicle_links(row['Dealer Details URL'], driver_path, max_vehicles=3)\n",
    "            await extract_vehicle_data(vehicle_links, dealer_data, driver_path, output_csv_file)\n",
    "\n",
    "\n",
    "# Start processing dealer URLs\n",
    "await open_dealer_urls(csv_file, output_csv_file, driver_path)\n",
    "\n",
    "# Load the data into a DataFrame for deduplication\n",
    "df = pd.read_csv(output_csv_file)\n",
    "\n",
    "# Identify rows that are duplicates of the header row by comparing against the first row\n",
    "header_row = df.iloc[0]\n",
    "df = df[~(df == header_row).all(axis=1)]\n",
    "\n",
    "# Save the cleaned data back to CSV\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "logging.info(\"Removed duplicate header rows and saved the cleaned CSV.\")\n",
    "\n",
    "# Confirm existence of the output CSV file path\n",
    "if os.path.exists(output_csv_file):\n",
    "    logging.info(f\"Output CSV path '{output_csv_file}' confirmed.\")\n",
    "else:\n",
    "    logging.error(f\"Output CSV path '{output_csv_file}' not found; please confirm the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba63a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csv_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
